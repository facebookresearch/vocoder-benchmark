# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.

# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
dataset:
  batch_size: 8
  frames_per_clip: 40
  clips_per_utterance: 10
  padding_frames: 2
  dataloader_num_workers: 4
  dataloader_prefetch_factor: 4

model:
  quantize_channels: 256  # 65536 or 256
  # This should equal to `quantize_channels` if mu-law quantize enabled
  # otherwise num_mixture * 3 (pi, mean, log_scale)
  # single mixture case: 2
  out_channels: 256
  layers: 24
  stacks: 4
  residual_channels: 128
  gate_channels: 256
  skip_out_channels: 128
  cin_channels: 80
  gin_channels: 1
  n_speakers: 7
  dropout: 0.0
  kernel_size: 3
  cin_pad: 2
  upsample_conditional_features: True
  # Input type:
  # 1. raw [-1, 1]
  # 2. mulaw [-1, 1]
  # 3. mulaw-quantize [0, mu]
  # If input_type is raw or mulaw, network assumes scalar input and
  # discretized mixture of logistic distributions output, otherwise one-hot
  # input and softmax output are assumed.
  input_type: "mulaw-quantize"
  output_distribution: "Normal" # Logistic or Normal
  n_iterations: 1500000
  learning_rate: 1.0e-3
  upsample_params:
    upsample_scales: [4, 5, 3, 5] # should np.prod(upsample_scales) == hop_size
    cin_channels: 80
    cin_pad: 2
  # see models/src/wavenet_vocoder/lrschedule.py for available lr_schedule
  lr_schedule: "step_learning_rate_decay"
  lr_schedule_kwargs:
    anneal_rate: 0.5
    anneal_interval: 200000
